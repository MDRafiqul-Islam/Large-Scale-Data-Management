{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQwXFyPUPwNhb+zNX44x+f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MDRafiqul-Islam/Large-Scale-Data-Management/blob/main/Tensor_Factorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDywPYRXVLPQ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eye(n):\n",
        "  lst = [[] for _ in range(n)]\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      if i == j:\n",
        "        lst[i].append(1)\n",
        "      else:\n",
        "        lst[i].append(0)\n",
        "  return np.array(lst)"
      ],
      "metadata": {
        "id": "x-67AVt5VQyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def qr_algorithm(A):\n",
        "  n = A.shape[0]\n",
        "  Q = eye(n)\n",
        "\n",
        "  for i in range(n - 1):\n",
        "    R = np.zeros((n, n))\n",
        "    Q_i = np.zeros((n, n))\n",
        "\n",
        "    for j in range(n):\n",
        "      R[j, j] = np.sqrt(np.sum(A[:, j] ** 2))\n",
        "      Q_i[:, j] = A[:, j] / R[j, j]\n",
        "      R[j, i] = np.sum(Q_i[:, j] * A[:, i])\n",
        "      A[:, i] = A[:, i] - R[j, i] * Q_i[:, j]\n",
        "    \n",
        "    A = R @ Q_i\n",
        "    Q = Q @ Q_i\n",
        "  \n",
        "  eigenvalues = np.diagonal(A)\n",
        "  eigenvectors = Q\n",
        "  \n",
        "  return eigenvalues, eigenvectors"
      ],
      "metadata": {
        "id": "r1vk9zbDVS49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def svd(A):\n",
        "    m, n = len(A), len(A[0])\n",
        "    AtA = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            for k in range(m):\n",
        "                AtA[i][j] += A[k][i]*A[k][j]\n",
        "    eigenvalues, eigenvectors = qr_algorithm(AtA)\n",
        "    singular_values = [math.sqrt(eigenvalue) for eigenvalue in eigenvalues]\n",
        "    V = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            V[i][j] = eigenvectors[i][j]\n",
        "    U = np.zeros((n, m))\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            U[i][j] = A[j][i]/singular_values[i]\n",
        "    return U, singular_values, V"
      ],
      "metadata": {
        "id": "tCadLyadVV_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reshape(array, dims):\n",
        "  if len(array) != np.prod(dims):\n",
        "    raise ValueError(\"Invalid dimensions for the reshaped array\")\n",
        "  return np.array(array).reshape(*dims)"
      ],
      "metadata": {
        "id": "9q0u1cjAVa0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def factor_tensor(T, rank=2):\n",
        "  # Checking if the rank of the tensor is valid\n",
        "  if rank > T.ndim or rank < 1:\n",
        "    raise ValueError(\"Invalid rank for the tensor\")\n",
        "\n",
        "  # Getting the shape of the tensor\n",
        "  shape = T.shape\n",
        "\n",
        "  # Reshapeing the tensor into a matrix\n",
        "  T_matrix = T.reshape((np.prod(shape[:rank]), np.prod(shape[rank:])))\n",
        "\n",
        "  U, S, V = svd(T_matrix)\n",
        "\n",
        "  # Initializeing the two factors with the left and right singular vectors\n",
        "  T1 = U.reshape(*shape[:rank], -1)\n",
        "  T2 = V.T.reshape(*shape[rank:], -1)\n",
        "  return T1, T2"
      ],
      "metadata": {
        "id": "wAiliRHUVc_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "T = np.random.rand(2, 3, 4)\n",
        "T1, T2 = factor_tensor(T, rank=2)\n",
        "print('T = ',T)\n",
        "print('T1 = ',T1,'\\n')\n",
        "print('T2 = ',T2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_ad_ffgVnVC",
        "outputId": "8f065656-504a-47f7-839a-b1e230057656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T =  [[[0.55588702 0.63585324 0.41202352 0.39953922]\n",
            "  [0.59039097 0.88256077 0.78206696 0.64029161]\n",
            "  [0.52735844 0.74556192 0.44568801 0.08942207]]\n",
            "\n",
            " [[0.7066232  0.67765118 0.27694301 0.04729824]\n",
            "  [0.27661446 0.94609625 0.53567458 0.61643817]\n",
            "  [0.53381337 0.6102942  0.81643408 0.88447244]]]\n",
            "T1 =  [[ 1.06083152  5.78013838 12.68149241]\n",
            " [ 4.04268768  4.31357604  1.28920275]] \n",
            "\n",
            "T2 =  [[ 1.20375332  1.74038611  1.33009801  1.14076433]\n",
            " [-0.25240411 -0.35619467 -0.26389684 -0.21717134]\n",
            " [ 1.37500906  1.98856051  1.5243148   1.31078107]\n",
            " [ 1.2950243   1.87323819  1.43287248  1.23012419]]\n"
          ]
        }
      ]
    }
  ]
}